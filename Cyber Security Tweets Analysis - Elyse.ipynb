{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d4cb08",
   "metadata": {},
   "source": [
    "# Cyber Security Tweet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(6,8)}) \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import SCORERS\n",
    "import re\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bf1bb",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f71e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function that takes in a range of values for K (or how many clusters)\n",
    "# runs the model and then outputs the inertia value so we can see how well the clusters are grouped \n",
    "\n",
    "\n",
    "def evaluate_k_kmeans_inertia(k, vec):\n",
    "    print(f\"running Kmeans with k={k}\")\n",
    "    estimator_kmeans = KMeans(random_state=42, n_clusters=k)\n",
    "    estimator_kmeans.fit(vec)\n",
    "    return estimator_kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250184c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, len_of_frame):\n",
    "    n = len(data.index) \n",
    "    split_n = round(n/len_of_frame, 0)\n",
    "    print(split_n)\n",
    "    splits = [int(x) for x in range(int(split_n))]\n",
    "    lst = []\n",
    "    for splt in splits:\n",
    "        if splt == splits[-1]:\n",
    "            lst.append(data[int(splt * len_of_frame):])\n",
    "        else:\n",
    "            lst.append(data[int(splt * len_of_frame):int(len_of_frame * (1 + splt))])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_summary(ci, df):\n",
    "    cluster = df[df.cluster_id==ci]\n",
    "    cluster_summary = cluster[categorical_data.columns].mode().to_dict(orient=\"records\")[0]\n",
    "    cluster_summary.update(cluster.mean().to_dict())\n",
    "    return cluster_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3780828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can make a function that puts comparisons side by side so its easier for us to see in a data frame \n",
    "\n",
    "def cluster_comparison(*cluster_ids):\n",
    "    summaries = []\n",
    "    for cluster_id in cluster_ids:\n",
    "        summaries.append(cluster_summary(cluster_id, df2))\n",
    "    return pd.DataFrame(summaries).set_index(\"cluster_id\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0311f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(df, n_clusters=2):\n",
    "    \"\"\"This function assigns clusters to every row in the dataframe via kmeans\"\"\"\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = model.fit_predict(df)\n",
    "    cluster_results = df.copy()\n",
    "    cluster_results['Cluster'] = clusters\n",
    "    return cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc305c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_summary_clustering(results):\n",
    "    \"\"\"this function produces a summary of the clusters\"\"\"\n",
    "    cluster_size = results.groupby(['Cluster']).size().reset_index()\n",
    "    cluster_size.columns = ['Cluster', 'Count']\n",
    "    cluster_means = results.groupby(['Cluster'], as_index=False).mean()\n",
    "    cluster_summary = pd.merge(cluster_size, cluster_means, on='Cluster')\n",
    "    cluster_summary = cluster_summary.drop([\"Count\"], axis=1).set_index(\"Cluster\")\n",
    "    return cluster_summary[sorted(cluster_summary.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6785d90",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859ab21",
   "metadata": {},
   "source": [
    "### Word Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3cd719",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_words = []\n",
    "\n",
    "for row in text['text']:\n",
    "    for word in str(row).split(\" \"):\n",
    "        cs_words.append(word)\n",
    "        \n",
    "cs_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist()\n",
    "for word in cs_words:\n",
    "    fdist[word]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7592d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_data = pd.DataFrame.from_dict(fdist.most_common(20))\n",
    "sns.barplot(data = freq_data, x = 1, y = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = []\n",
    "\n",
    "for key in fdist.most_common(25):\n",
    "    most_common.append(key[0])\n",
    "    \n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf77b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "new_stopwords=stopwords.union(text)\n",
    "wc = WordCloud(\n",
    "         background_color=\"white\", max_words=2000, \n",
    "         min_font_size =15, max_font_size=40, relative_scaling = \n",
    "         0.5, stopwords=new_stopwords,normalize_plurals= True)\n",
    "import re \n",
    "textonly = re.sub(\" \", \" \",str(text))\n",
    "wc.generate(textonly)\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Show the wordcloud\n",
    "plt.show()\n",
    "# devil is interesting, Intel is possibly the company, \n",
    "# Jeanette Manfra is commonly found when searching jeannette\n",
    "# and cybersecurity\n",
    "# Microsoft Azure Sentinel is a scalable, cloud-native, security information \n",
    "# event management (SIEM) and security orchestration automated response (SOAR) solution. \n",
    "# Los Angeles and Pakistan are the only locations, chinese is only nationality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbebb85",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "text['scores'] = text['text'].apply(lambda review: sid.polarity_scores(review))\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text['compound']  = text['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ded3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text['comp_score'] = text['compound'].apply(lambda c: 'pos' if c >=0.05 else ('neg' if c <= -0.05 else 'neutral'))\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a48ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "comp_score_counts = text.comp_score.value_counts()\n",
    "comp_score_counts.plot.pie(autopct=\"%.1f%%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bac4a7",
   "metadata": {},
   "source": [
    "### Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09797f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "range_k = [i for i in range(1, 9)]\n",
    "results_k = {}\n",
    "for k in range_k:\n",
    "    results_k[k] = evaluate_k_kmeans_inertia(k, text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now plot this to see where the inflection point is or where adding more clusters doesnt really add to gaining\n",
    "# more information from extra clusters\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax = sns.lineplot(\n",
    "    [c[0] for c in results_k.items()],\n",
    "    [c[1] for c in results_k.items()], label=\"inertia\", color=\"red\")\n",
    "ax.set_xlabel(\"K\")\n",
    "ax.set_ylabel(\"inertia\")\n",
    "ax.set_title(\"Inertia by K\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_kmeans = KMeans(random_state=42, n_clusters=6) # making it 6 now to see what happens\n",
    "\n",
    "estimator_kmeans.fit(text_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1bf6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec[\"cluster_id\"] = estimator_kmeans.labels_\n",
    "text_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clusters = text_vec.groupby('cluster_id').sum()\n",
    "text_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21030330",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clusters_20 = text_clusters[['data', 'new', 'attack', 'infosec', 'ransomware', 'amp', 'business', 'threat', 'hacker', 'ai', 'hacking', 'cyberattack', 'company', 'learn', 'risk', '2021', 'ethicalhacking', 'cloud', 'cybersecuritytips', 'cybersecuritynews', 'iotcybersec24', 'help', 'system', 'need']]\n",
    "text_clusters_20.head() # only focusing on top 20 post popular words ('u' not in data frame oddly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99163b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,15))\n",
    "sns.heatmap(text_clusters_20.transpose(), annot=False)\n",
    "plt.title(\"Cluster Analysis based on Twitter Posts using the Top 25 Words\", size = 30);\n",
    "# Look for rows with a lot of variation to see defining features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4dda4",
   "metadata": {},
   "source": [
    "## Indentifying Variable Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c9f9b",
   "metadata": {},
   "source": [
    "### Word Frequency | Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe756d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words = []\n",
    "\n",
    "for row in desc['description']:\n",
    "    for word in str(row).split(\" \"):\n",
    "        desc_words.append(word)\n",
    "        \n",
    "desc_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_desc = FreqDist()\n",
    "for word in desc_words:\n",
    "    fdist_desc[word]+=1\n",
    "fdist_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_data_desc = pd.DataFrame.from_dict(fdist_desc.most_common(20))\n",
    "sns.barplot(data = freq_data_desc, x = 1, y = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3eef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_desc = []\n",
    "\n",
    "for key in fdist_desc.most_common(20):\n",
    "    most_common_desc.append(key[0])\n",
    "    \n",
    "most_common_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f47c49",
   "metadata": {},
   "source": [
    "### Cluster Analysis | Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "range_k = [i for i in range(1, 9)]\n",
    "results_k = {}\n",
    "for k in range_k:\n",
    "    results_k[k] = evaluate_k_kmeans_inertia(k, desc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f820b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax = sns.lineplot(\n",
    "    [c[0] for c in results_k.items()],\n",
    "    [c[1] for c in results_k.items()], label=\"inertia\", color=\"red\")\n",
    "ax.set_xlabel(\"K\")\n",
    "ax.set_ylabel(\"inertia\")\n",
    "ax.set_title(\"Inertia by K\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b51974",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_kmeans = KMeans(random_state=42, n_clusters=5) # 5 for now (the elbow curve is janky)\n",
    "\n",
    "estimator_kmeans.fit(desc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_vec[\"cluster_id\"] = estimator_kmeans.labels_\n",
    "desc_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_clusters = desc_vec.groupby('cluster_id').sum()\n",
    "desc_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d63ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_clusters_20 = desc_clusters[['business',\n",
    " 'technology',\n",
    " 'service',\n",
    " 'solution',\n",
    " 'news',\n",
    " 'digital',\n",
    " 'tech',\n",
    " 'data',\n",
    " 'cloud',\n",
    " 'company',\n",
    " 'help',\n",
    " 'tweet',\n",
    " 'information',\n",
    " 'world',\n",
    " 'software',\n",
    " 'management',\n",
    " 'global',\n",
    " 'ai',\n",
    " 'professional']]\n",
    "\n",
    "desc_clusters_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,15))\n",
    "sns.heatmap(desc_clusters_20.transpose(), annot=False)\n",
    "plt.title(\"Cluster Analysis based on Twitter Description using the Top 20 Words\", size = 30);\n",
    "# Look for rows with a lot of variation to see defining features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72607d7",
   "metadata": {},
   "source": [
    "### Cluster Analysis | Other Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260416d",
   "metadata": {},
   "source": [
    "#### Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ident = data[[\"created_at\", \"is_quote\", \"retweet_count\", \"location\", \"followers_count\", \"friends_count\", \"listed_count\", \"account_created_at\", \"verified\"]][:1000]\n",
    "ident.head() # remove is_retweet and protected, no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e088d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = ident.select_dtypes(np.number)\n",
    "categorical_data = ident.drop(numerical_data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28804603",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data_normalized = MinMaxScaler().fit_transform(numerical_data) # this line scales our data\n",
    "\n",
    "numerical_data_normalized = pd.DataFrame(              #this pops it back in data frame format \n",
    "    numerical_data_normalized,\n",
    "    columns=numerical_data.columns) \n",
    "\n",
    "numerical_data_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data_codified = pd.get_dummies(\n",
    "                                    categorical_data, \n",
    "                                    drop_first=True,\n",
    "                                    dtype=\"int64\"\n",
    ").reset_index()\n",
    "categorical_data_codified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_processed = pd.concat([\n",
    "                            numerical_data_normalized,\n",
    "                            categorical_data_codified\n",
    "                        ], axis=1\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c5a37",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b95a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "range_k = [2, 3, 4, 5, 8, 10, 15, 20, 25, 30]\n",
    "results_k = {}\n",
    "for k in range_k:\n",
    "    results_k[k] = evaluate_k_kmeans_inertia(k, df2_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax = sns.lineplot(\n",
    "    [c[0] for c in results_k.items()],\n",
    "    [c[1] for c in results_k.items()], label=\"inertia\", color=\"red\")\n",
    "ax.set_xlabel(\"K\")\n",
    "ax.set_ylabel(\"inertia\")\n",
    "ax.set_title(\"Inertia by K\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_kmeans = KMeans(random_state=42, n_clusters=10) # 5 for now (the elbow curve is janky)\n",
    "\n",
    "estimator_kmeans.fit(df2_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c573023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"cluster_id\"] = estimator_kmeans.labels_\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbe398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.cluster_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caeb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_comparison(0,1,2,3,4,5,6,7,8,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289424ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = kmeans_cluster(df2_processed, 5)\n",
    "cluster_summary2 = graph_summary_clustering(cluster_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8941927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_summary2 = cluster_summary2.drop('cluster_id', axis = 1)\n",
    "cluster_summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1812dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cluster_summary2.transpose(), annot=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
